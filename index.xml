<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Priyam Das</title>
    <link>https://priyamdas.github.io/</link>
      <atom:link href="https://priyamdas.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Priyam Das</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 25 Aug 2021 19:17:29 -0700</lastBuildDate>
    <image>
      <url>https://priyamdas.github.io/images/icon_huf8e3127d14e503ab69ceb2be5b6e95b6_12081_512x512_fill_lanczos_center_2.png</url>
      <title>Priyam Das</title>
      <link>https://priyamdas.github.io/</link>
    </image>
    
    <item>
      <title>The Effects of Human Autonomy on Engagement</title>
      <link>https://priyamdas.github.io/post/autonomy-engagement/</link>
      <pubDate>Wed, 25 Aug 2021 19:17:29 -0700</pubDate>
      <guid>https://priyamdas.github.io/post/autonomy-engagement/</guid>
      <description>&lt;p&gt;When scientists usually run human behavioral experiments, especially online, the researcher has total control over the experiment flow and the participant simply reacts to the stimuli presented. This works well enough, but we wondered whether giving participants more agency during the experiment would have an effect on their engagement and performance on the task. To investigate this we devised a series of classification tasks where, depending on the task, participants are allowed to choose the category of images that they label, the number of images in each category to label, or even when to quit the experiment. The accuracy and number of images classified of participants who are given agency is compared to those of participants who aren’t given any agency and go through a “traditional” version of the task, where the length of the experiment and all of the stimuli are decided in advance. Should we find an effect on task performance due to agency, then we believe that this finding would have implications not only for behavioral research design, but also for how tasks are structured and delegated in the workplace.&lt;/p&gt;
&lt;p&gt;We ran two online experiments to investigate the effect of agency on task engagement and performance. In both experiments, participants were asked to label images of common grocery store items such as produce and dairy. These images were grouped into 12 categories such as citrus fruits, root vegetables, fruit juice, and dairy substitutes. Before the classification task began, participants were able to practice on some example images, allowing them to familiarize themselves with the interface and task.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sample-trial.png&#34; alt=&#34;&#34; title=&#34;A sample classification trial from the &#39;Melons&#39; category.&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the first experiment, participants were either put in the free choice condition, where they could choose the category of images they wanted to classify, or the forced choice condition where the categories were selected for the participant. In both conditions, participants had the option to quit the experiment whenever they wanted after going through one category’s worth of images. We hypothesized that those in the free choice condition would complete more categories and also have higher classification accuracy compared to those in the forced choice condition, due to being more engaged in the task. You can try this version of the experiment 
&lt;a href=&#34;https://grocery-images.web.app/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;no-choice.png&#34; alt=&#34;&#34; title=&#34;The selection screen shown to participants in the forced choice condition. The red circle has been added for emphasis and was not seen by participants.&#34;&gt;&lt;/p&gt;
&lt;p&gt;We found the opposite, where people in the forced choice condition completed more categories than those with the freedom to choose, and that classification accuracy was similar between both groups. Perhaps the participants with freedom to choose felt more empowered to end the experiment early or perhaps those who weren’t given any freedom expected the experiment to end on its own accord, like so many other traditional online experiments. We decided to get rid of the option to quit for the next experiment, since it seemed to confuse some participants.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;main_effects1.png&#34; alt=&#34;&#34; title=&#34;Participants in the forced choice condition completed more image classifications than participants in the free choice condition.&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the second experiment, we again had free choice and forced choice conditions, except this time every participant would classify the same number of images. The freedom allowed to some participants in this case was to change the category of images whenever they desired, whereas those in the forced choice condition would only stay in one category for the whole experiment. We hypothesized again that those who had the choice to switch categories would have higher classification accuracy compared those who had no choice because we thought that those who had no choice would get bored faster and that would affect accuracy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;switch-choice.png&#34; alt=&#34;&#34; title=&#34;This time instead of a selection screen with different categories, we added a switch button on the classification screen itself. The blue arrow has been added for emphasis.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Again, we found that the accuracy between both conditions was similar. It is possible that the task was too short to allow for boredom to set in properly, or that even given choice, the task wasn’t engaging enough to have an effect on performance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;maineffect2.png&#34; alt=&#34;&#34; title=&#34;There was no difference in accuracy between the two conditions.&#34;&gt;&lt;/p&gt;
&lt;p&gt;To further investigate the effects of agency on performance, it might be useful to run longer, possibly longitudinal, experiments to see if one group is more willing to complete the classification task compared to the other. Or, it might be helpful to use a different task entirely, perhaps one where having choices makes a significant difference in user experience compared to not having choices. While we hoped to find a new way of designing effective behavioral experiments, as it stands, the question remains as to whether giving participants agency improves their performance on an experiment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://priyamdas.github.io/research/</link>
      <pubDate>Wed, 27 May 2020 10:39:20 -0700</pubDate>
      <guid>https://priyamdas.github.io/research/</guid>
      <description>&lt;h4 id=&#34;how-percieved-effort-affects-resistance-to-learning-new-tools&#34;&gt;How Percieved Effort Affects Resistance to Learning New Tools&lt;/h4&gt;
&lt;p&gt;




  
  











&lt;figure id=&#34;figure-these-three-smart-ovens-can-produce-cakes-of-varying-quality-which-one-would-you-spend-your-time-on-mastering-try-it-out-herehttpstoolswitchingwebapp&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://priyamdas.github.io/research/tools_hu5c13728bb1f1efbdb8bf85efdc42e991_389939_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;These three smart ovens can produce cakes of varying quality. Which one would you spend your time on mastering? Try it out here.&#34;&gt;


  &lt;img data-src=&#34;https://priyamdas.github.io/research/tools_hu5c13728bb1f1efbdb8bf85efdc42e991_389939_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1200&#34; height=&#34;900&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    These three smart ovens can produce cakes of varying quality. Which one would you spend your time on mastering? Try it out &lt;a href=&#34;https://toolswitching.web.app/&#34;&gt;here.&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

Many of us are familiar with asking someone to use a new software or technology and being met with resistance to the change. Perhaps you&amp;rsquo;ve even felt it yourself, feeling that the tool you currently use works well enough and that the new tool doesn&amp;rsquo;t warrant the effort needed to learn it. To investigate how this resistance to new tools relates to the effort required to learn the tool and the age of the user, I&amp;rsquo;ve designed a set of studies which ask people to learn to use kitchen appliances of varying difficulty. You can try one of the experiments 
&lt;a href=&#34;https://toolswitching.web.app/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;the-effect-of-practice-in-overcoming-age-related-performance-gaps&#34;&gt;The Effect of Practice in Overcoming Age-Related Performance Gaps&lt;/h4&gt;
&lt;p&gt;




  
  











&lt;figure id=&#34;figure-shown-here-are-the-probabilities-of-an-older-adult-catching-up-to-a-younger-adult-on-lumosity-games-testing-different-cognitive-abilities-values-of-at-least-050-mean-that-an-older-adult-who-practiced-80-more-times-than-a-younger-adult-was-able-to-beat-the-younger-adults-score-the-axis-numbers-are-decade-markers-such-that-50-represents-those-users-50-59-years-old-and-60-means-60-69-years-old-etc&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://priyamdas.github.io/research/catchup_hu54d91a2bab3bb3210b563591de8feb7d_307024_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Shown here are the probabilities of an older adult catching up to a younger adult on Lumosity games testing different cognitive abilities. Values of at least 0.50 mean that an older adult who practiced 80 more times than a younger adult was able to beat the younger adult&amp;rsquo;s score. The axis numbers are decade markers, such that &amp;ldquo;50&amp;rdquo; represents those users 50-59 years old and &amp;ldquo;60&amp;rdquo; means 60-69 years old, etc.&#34;&gt;


  &lt;img data-src=&#34;https://priyamdas.github.io/research/catchup_hu54d91a2bab3bb3210b563591de8feb7d_307024_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2773&#34; height=&#34;1964&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Shown here are the probabilities of an older adult catching up to a younger adult on Lumosity games testing different cognitive abilities. Values of at least 0.50 mean that an older adult who practiced 80 more times than a younger adult was able to beat the younger adult&amp;rsquo;s score. The axis numbers are decade markers, such that &amp;ldquo;50&amp;rdquo; represents those users 50-59 years old and &amp;ldquo;60&amp;rdquo; means 60-69 years old, etc.
  &lt;/figcaption&gt;


&lt;/figure&gt;

It&amp;rsquo;s been fairly well studied that younger adults learn faster and perform better on cognitive tasks testing memory and multitasking ability compared to adults even just 10 years older. This performance gap only increases as the age gap gets larger. However, could the older person ever match or even surpass the younger person&amp;rsquo;s performance given unlimited time to practice the task?
I investigated this question using data obtained from users of the popular brain training website 
&lt;a href=&#34;https://www.lumosity.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lumosity&lt;/a&gt;. I analyzed the performance data of nearly 10,000 users aged 18-90 years old and found that if older adults practice more than younger adults,the probability of older adults catching up to younger adults increases. Additionally, the extra practice allows older adults to match the performance of adults up to 20 years younger in many games (see graphic above). This work was peer-reviewed and you can read the published paper 
&lt;a href=&#34;https://doi.org/10.1525/collabra.88156&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;how-autonomy-affects-task-engagement&#34;&gt;How Autonomy Affects Task Engagement&lt;/h4&gt;
&lt;p&gt;




  
  











&lt;figure id=&#34;figure-participants-are-given-the-option-to-choose-the-types-of-images-to-classify-you-can-try-this-experiment-for-yourself-herehttpsgrocery-imageswebapp&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://priyamdas.github.io/research/choice_hu7cacd743dac003bcf57fd1d96e3be5e3_161966_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Participants are given the option to choose the types of images to classify. You can try this experiment for yourself here.&#34;&gt;


  &lt;img data-src=&#34;https://priyamdas.github.io/research/choice_hu7cacd743dac003bcf57fd1d96e3be5e3_161966_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1483&#34; height=&#34;868&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Participants are given the option to choose the types of images to classify. You can try this experiment for yourself &lt;a href=&#34;https://grocery-images.web.app/&#34;&gt;here&lt;/a&gt;.
  &lt;/figcaption&gt;


&lt;/figure&gt;

When scientists usually run human behavioral experiments, especially online, the researcher has total control over the experiment flow and the participant simply reacts to the stimuli presented. This works well enough, but we wondered whether giving participants more agency during the experiment would have an effect on their engagement and performance on the task. To investigate this we devised a series of classification tasks where, depending on the task, participants are allowed to choose the category of images that they label, the number of images in each category to label, or even when to quit the experiment. The accuracy and number of images classified of participants who are given agency is compared to those of participants who aren&amp;rsquo;t given any agency and go through a &amp;ldquo;traditional&amp;rdquo; version of the task.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://priyamdas.github.io/post/autonomy-engagement/&#34;&gt;Read more here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
